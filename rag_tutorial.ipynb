{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4vrP9ys3hwqxLmt31ej5X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chizhikchi/gdg_menorca_RAG_tutorial/blob/main/rag_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ü§ì Tutorial: RAG (Retrieval-Augmented Generation) con Vertex AI:\n",
        "Este tutorial muestra c√≥mo crear un sistema RAG usando Vertex AI de Google Cloud.\n"
      ],
      "metadata": {
        "id": "_ZihqLe_H5sc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1A5fYgEe6c3m0brN0TtnMCNouC7q-Csgz?usp=sharing)"
      ],
      "metadata": {
        "id": "CBWsQvf9Jwx-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iuOPDDB6HsPc"
      },
      "outputs": [],
      "source": [
        "# importamos las dependencias necesarias\n",
        "import os\n",
        "from pathlib import Path\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "import vertexai\n",
        "from vertexai import rag\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîê Configuramos los secretos\n",
        "Guardaremos todas las credenciasles en Google Colab Secrets.\n",
        "Ve a la secci√≥n de secretos (üîë) en el lateral izquierdo para configurarlos"
      ],
      "metadata": {
        "id": "8rsH18jgIP3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Authenticate your notebook environment (colab only)\n",
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ],
      "metadata": {
        "id": "mvMem82wKyu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID = userdata.get('PROJECT_ID')        # ID de tu proyecto de Google Cloud\n",
        "LOCATION = \"us-central1\"                       # Regi√≥n donde crear el corpus\n",
        "CORPUS_NAME = \"Hotel_RAG_Corpus0\"                  # Nombre para identificar el corpus\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_KEY') # Tu clave API de Gemini\n",
        "\n",
        "# Inicializamos Vertex AI\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "\n",
        "# Inicializar cliente de Gemini\n",
        "client = genai.Client(api_key=GEMINI_API_KEY)\n",
        "\n",
        "print(\"‚úÖ Configuraci√≥n completada\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUOPRstsIN8K",
        "outputId": "03364778-8d66-4043-ba13-abfa2948c686"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Configuraci√≥n completada\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üóû Crear el corpus RAG\n",
        "Subimos nuestros documentos."
      ],
      "metadata": {
        "id": "szLXNMXPJSeN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def crear_corpus():\n",
        "    \"\"\"Crea un nuevo corpus RAG en Vertex AI\"\"\"\n",
        "    try:\n",
        "        # Configuraci√≥n del modelo de embeddings\n",
        "        embedding_config = rag.RagEmbeddingModelConfig(\n",
        "            vertex_prediction_endpoint=rag.VertexPredictionEndpoint(\n",
        "                publisher_model=\"publishers/google/models/text-embedding-005\"\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Crear el corpus\n",
        "        corpus = rag.create_corpus(\n",
        "            display_name=CORPUS_NAME,\n",
        "            backend_config=rag.RagVectorDbConfig(\n",
        "                rag_embedding_model_config=embedding_config\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        print(f\"‚úÖ Corpus creado: {corpus.name}\")\n",
        "        return corpus\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error al crear corpus: {e}\")\n",
        "        return None\n",
        "\n",
        "# Crear el corpus\n",
        "corpus = crear_corpus()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwQYTQHZJoWF",
        "outputId": "707559d1-6f2d-4d2a-e17c-3b18e8e5f3a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Corpus creado: projects/103632863401/locations/us-central1/ragCorpora/1901081992703770624\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparamos los archivos para su subida"
      ],
      "metadata": {
        "id": "FAB1R0S0LMtC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Montar Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Ruta a la carpeta de documentos generados en Drive\n",
        "docs_dir = Path('/content/drive/MyDrive/Charlas/Taller-Menorca/documentos_generados')\n",
        "\n",
        "# Verificar que la carpeta existe\n",
        "if not docs_dir.exists():\n",
        "    print(f\"‚ùå No se encontr√≥ la carpeta: {docs_dir}\")\n",
        "    print(\"Por favor, aseg√∫rate de que existe la carpeta 'documentos generados' en tu Google Drive\")\n",
        "else:\n",
        "    # Listar archivos .txt disponibles\n",
        "    archivos_txt = list(docs_dir.glob(\"*.txt\"))\n",
        "    print(f\"üìÅ Carpeta encontrada: {docs_dir}\")\n",
        "    print(f\"üìÑ Archivos .txt encontrados: {len(archivos_txt)}\")\n",
        "\n",
        "    for archivo in archivos_txt:\n",
        "        print(f\"  ‚Ä¢ {archivo.name}\")\n",
        "\n",
        "    if len(archivos_txt) == 0:\n",
        "        print(\"‚ö†Ô∏è  No se encontraron archivos .txt en la carpeta\")\n",
        "        print(\"Aseg√∫rate de que hay documentos .txt en 'documentos generados'\")\n",
        "    else:\n",
        "        print(\"‚úÖ Documentos listos para subir al corpus\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAppvrMbJ07c",
        "outputId": "e311a329-3203-48bf-82ff-fd34fe0a2866"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "üìÅ Carpeta encontrada: /content/drive/MyDrive/Charlas/Taller-Menorca/documentos_generados\n",
            "üìÑ Archivos .txt encontrados: 1\n",
            "  ‚Ä¢ Hotel Overview.txt\n",
            "‚úÖ Documentos listos para subir al corpus\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Subimos los documentos a VertexAI"
      ],
      "metadata": {
        "id": "nEmwJ--3MKVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def subir_documentos(corpus, directorio_docs):\n",
        "    \"\"\"Sube todos los archivos .txt de un directorio al corpus\"\"\"\n",
        "    if not corpus:\n",
        "        print(\"‚ùå No hay corpus disponible\")\n",
        "        return False\n",
        "\n",
        "    archivos_txt = list(Path(directorio_docs).glob(\"*.txt\"))\n",
        "    if not archivos_txt:\n",
        "        print(\"‚ùå No se encontraron archivos .txt\")\n",
        "        return False\n",
        "\n",
        "    print(f\"üì§ Subiendo {len(archivos_txt)} documentos...\")\n",
        "\n",
        "    exitosos = 0\n",
        "    for archivo in archivos_txt:\n",
        "        try:\n",
        "            rag.upload_file(\n",
        "                corpus_name=corpus.name,\n",
        "                path=str(archivo),\n",
        "                display_name=archivo.name,\n",
        "                description=f\"Documento: {archivo.stem}\"\n",
        "            )\n",
        "            print(f\"  ‚úÖ {archivo.name}\")\n",
        "            exitosos += 1\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  ‚ùå Error en {archivo.name}: {e}\")\n",
        "\n",
        "    print(f\"‚úÖ Subida completada: {exitosos}/{len(archivos_txt)} archivos\")\n",
        "    return exitosos == len(archivos_txt)\n",
        "\n",
        "# Subir los documentos\n",
        "subida_exitosa = subir_documentos(corpus, docs_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FyqjaU5Lxcd",
        "outputId": "44f71116-2665-4ace-efb0-7040e0a564d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì§ Subiendo 1 documentos...\n",
            "  ‚úÖ Hotel Overview.txt\n",
            "‚úÖ Subida completada: 1/1 archivos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üå• Verificar el estado del corpus\n",
        "Comprobamos que los documentos se han subido correctamente"
      ],
      "metadata": {
        "id": "57oKKKjeMYVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def verificar_corpus(corpus):\n",
        "    \"\"\"Muestra informaci√≥n sobre el corpus y sus documentos\"\"\"\n",
        "    if not corpus:\n",
        "        print(\"‚ùå No hay corpus para verificar\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        print(f\"üìö Corpus: {corpus.display_name}\")\n",
        "        print(f\"üÜî ID: {corpus.name}\")\n",
        "\n",
        "        # Listar archivos en el corpus\n",
        "        archivos = list(rag.list_files(corpus_name=corpus.name))\n",
        "        print(f\"üìÑ Documentos en el corpus: {len(archivos)}\")\n",
        "\n",
        "        for archivo in archivos:\n",
        "            print(f\"  ‚Ä¢ {archivo.display_name}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error al verificar corpus: {e}\")\n",
        "\n",
        "# Verificar el corpus\n",
        "verificar_corpus(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-RuYmC9MOfm",
        "outputId": "c899575d-4111-470c-cd7d-4e43f55a054c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìö Corpus: Hotel_RAG_Corpus0\n",
            "üÜî ID: projects/103632863401/locations/us-central1/ragCorpora/1901081992703770624\n",
            "üìÑ Documentos en el corpus: 1\n",
            "  ‚Ä¢ Hotel Overview.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üó£ Configurar el chat con RAG\n",
        "Preparamos la funci√≥n para hacer preguntas usando el corpus como fuente"
      ],
      "metadata": {
        "id": "Aqmh1ZJprm_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from vertexai.generative_models import GenerativeModel, Tool\n",
        "import vertexai.preview.generative_models as generative_models\n",
        "\n",
        "def chat_con_rag(pregunta, corpus, modelo=\"gemini-2.5-flash-lite\"):\n",
        "    \"\"\"Realiza una consulta usando RAG con el corpus creado\"\"\"\n",
        "    if not corpus:\n",
        "        return \"‚ùå No hay corpus disponible\"\n",
        "\n",
        "    try:\n",
        "        # Configurar la herramienta RAG\n",
        "        rag_retrieval_tool = Tool.from_retrieval(\n",
        "            retrieval=rag.Retrieval(\n",
        "                source=rag.VertexRagStore(\n",
        "                    rag_resources=[\n",
        "                        rag.RagResource(\n",
        "                            rag_corpus=corpus.name,\n",
        "                        )\n",
        "                    ],\n",
        "                ),\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Inicializar el modelo con la herramienta RAG\n",
        "        model = GenerativeModel(\n",
        "            model_name=modelo,\n",
        "            tools=[rag_retrieval_tool],\n",
        "        )\n",
        "\n",
        "        # Configuraci√≥n de generaci√≥n\n",
        "        generation_config = generative_models.GenerationConfig(\n",
        "            temperature=0.7,\n",
        "            top_p=0.9,\n",
        "            max_output_tokens=1000,\n",
        "        )\n",
        "\n",
        "        # Realizar la consulta\n",
        "        chat = model.start_chat()\n",
        "        response = chat.send_message(\n",
        "            pregunta,\n",
        "            generation_config=generation_config,\n",
        "        )\n",
        "\n",
        "        return response.text\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Error en la consulta: {e}\""
      ],
      "metadata": {
        "id": "Tm7agtM5MlTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_con_rag(\"¬øQu√© servicios ofrece el hotel?\", corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "OepaBRXMswc7",
        "outputId": "eaab9f91-0781-4357-ddbb-645a64bfdf60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'El GDG Menorca Resort ofrece habitaciones y suites elegantes, √°reas de juego seguras, piscinas para ni√±os, programa de actividades supervisadas, restaurantes con ambientes rom√°nticos, servicios de spa, salas de reuniones equipadas con tecnolog√≠a de vanguardia y conectividad de alta velocidad.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üñ• Interfaz Gradio para el chat"
      ],
      "metadata": {
        "id": "e-pLW8Pnuv9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def responder_pregunta(pregunta, historial):\n",
        "    \"\"\"Funci√≥n que maneja las preguntas del usuario en la interfaz Gradio\"\"\"\n",
        "    if not corpus:\n",
        "        return historial + [[\"Sistema no disponible\", \"‚ùå El corpus RAG no est√° disponible\"]]\n",
        "\n",
        "    if not pregunta.strip():\n",
        "        return historial + [[\"\", \"Por favor, escribe una pregunta\"]]\n",
        "\n",
        "    # Obtener respuesta del sistema RAG\n",
        "    respuesta = chat_con_rag(pregunta, corpus)\n",
        "\n",
        "    # A√±adir la conversaci√≥n al historial\n",
        "    historial = historial + [[pregunta, respuesta]]\n",
        "\n",
        "    return historial, \"\"\n",
        "\n",
        "# Crear la interfaz Gradio\n",
        "with gr.Blocks(title=\"üè® Chat RAG - Hotel Assistant\") as demo:\n",
        "    gr.Markdown(\"# üè® Asistente Virtual del Hotel\")\n",
        "    gr.Markdown(\"Haz preguntas sobre nuestro hotel y servicios. El sistema usar√° RAG para darte respuestas precisas.\")\n",
        "\n",
        "    # Mostrar estado del corpus\n",
        "    if corpus:\n",
        "        gr.Markdown(f\"‚úÖ **Sistema RAG activo** - Corpus: {CORPUS_NAME}\")\n",
        "    else:\n",
        "        gr.Markdown(\"‚ùå **Sistema RAG no disponible** - Verifica la configuraci√≥n del corpus\")\n",
        "\n",
        "    chatbot = gr.Chatbot(\n",
        "        height=400,\n",
        "        label=\"Conversaci√≥n\",\n",
        "        value=[],\n",
        "        avatar_images=[\"https://images-wixmp-ed30a86b8c4ca887773594c2.wixmp.com/f/45c7dd7e-6cef-4101-93b9-df6da53c9ac7/dc8bfoe-9f7c1793-aedd-4753-8b8b-d0a3ec4f41bd.png/v1/fill/w_1024,h_920/emoji_frog_from_facebook__emoji_de_facebook__by_thebether_dc8bfoe-fullview.png?token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJ1cm46YXBwOjdlMGQxODg5ODIyNjQzNzNhNWYwZDQxNWVhMGQyNmUwIiwiaXNzIjoidXJuOmFwcDo3ZTBkMTg4OTgyMjY0MzczYTVmMGQ0MTVlYTBkMjZlMCIsIm9iaiI6W1t7ImhlaWdodCI6Ijw9OTIwIiwicGF0aCI6IlwvZlwvNDVjN2RkN2UtNmNlZi00MTAxLTkzYjktZGY2ZGE1M2M5YWM3XC9kYzhiZm9lLTlmN2MxNzkzLWFlZGQtNDc1My04YjhiLWQwYTNlYzRmNDFiZC5wbmciLCJ3aWR0aCI6Ijw9MTAyNCJ9XV0sImF1ZCI6WyJ1cm46c2VydmljZTppbWFnZS5vcGVyYXRpb25zIl19.ceNqrz85wnxMxzu5aLOSp5wNWI0hq1oEWd05Iw2FR5A\", \"https://res.cloudinary.com/startup-grind/image/upload/c_fill,w_500,h_500,g_center/c_fill,dpr_2.0,f_auto,g_center,q_auto:good/v1/gcs/platform-data-goog/events/BWAI25-EventThumb-01_HvLFtd8.png\"]\n",
        "    )\n",
        "\n",
        "    with gr.Row():\n",
        "        pregunta_input = gr.Textbox(\n",
        "            placeholder=\"Escribe tu pregunta sobre el hotel...\",\n",
        "            label=\"Tu pregunta\",\n",
        "            scale=4\n",
        "        )\n",
        "        enviar_btn = gr.Button(\"Enviar\", variant=\"primary\", scale=1)\n",
        "\n",
        "    # Ejemplos de preguntas\n",
        "    gr.Examples(\n",
        "        examples=[\n",
        "            \"¬øQu√© servicios ofrece el hotel?\",\n",
        "            \"¬øCu√°les son los tipos de habitaciones disponibles?\",\n",
        "            \"¬øCu√°l es la pol√≠tica de cancelaci√≥n?\",\n",
        "            \"¬øSe admiten mascotas?\",\n",
        "            \"¬øHay actividades para ni√±os?\",\n",
        "            \"¬øCu√°les son los horarios de check-in y check-out?\"\n",
        "        ],\n",
        "        inputs=pregunta_input,\n",
        "        label=\"Preguntas de ejemplo\"\n",
        "    )\n",
        "\n",
        "    # Bot√≥n para limpiar la conversaci√≥n\n",
        "    limpiar_btn = gr.Button(\"üóëÔ∏è Limpiar conversaci√≥n\", variant=\"secondary\")\n",
        "\n",
        "    # Eventos\n",
        "    enviar_btn.click(\n",
        "        responder_pregunta,\n",
        "        inputs=[pregunta_input, chatbot],\n",
        "        outputs=[chatbot, pregunta_input]\n",
        "    )\n",
        "\n",
        "    pregunta_input.submit(\n",
        "        responder_pregunta,\n",
        "        inputs=[pregunta_input, chatbot],\n",
        "        outputs=[chatbot, pregunta_input]\n",
        "    )\n",
        "\n",
        "    limpiar_btn.click(\n",
        "        lambda: ([], \"\"),\n",
        "        outputs=[chatbot, pregunta_input]\n",
        "    )\n",
        "\n",
        "# Lanzar la interfaz\n",
        "print(\"üöÄ Iniciando interfaz Gradio...\")\n",
        "demo.launch(share=False, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "id": "MID3ZZhwsGBj",
        "outputId": "0164debe-d1fb-47c0-d728-55af783539af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-21-3751887410.py:30: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Iniciando interfaz Gradio...\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "* To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7860, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/vertexai/generative_models/_generative_models.py:433: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
            "  warning_logs.show_deprecation_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > requirements.txt"
      ],
      "metadata": {
        "id": "GE--iwM2selE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ApAl8IjtJgZq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}